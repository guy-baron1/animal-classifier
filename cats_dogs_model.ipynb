{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\r\n",
    "import time\r\n",
    "import random\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\r\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\r\n",
    "\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "images_dir = './PetImages'\r\n",
    "categories = ['Dog', 'Cat']\r\n",
    "img_size = 70\r\n",
    "# grayscale pixel: 0-255, rgb pixel: [0-255, 0-255, 0-255]\r\n",
    "flag_to_channel_count = {\r\n",
    "    cv2.IMREAD_GRAYSCALE: 1,\r\n",
    "    cv2.IMREAD_COLOR: 3\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def create_training_data(flag):\r\n",
    "    training_data = []\r\n",
    "    channel_count = flag_to_channel_count[flag]\r\n",
    "    for category in categories:\r\n",
    "        path = os.path.join(images_dir, category)\r\n",
    "        class_num = categories.index(category) # dog == 0, cat == 1\r\n",
    "        for img in os.listdir(path):\r\n",
    "            try:\r\n",
    "                img_arr = cv2.imread(os.path.join(path, img), flag)\r\n",
    "                resized_img_arr = cv2.resize(img_arr, (img_size, img_size))\r\n",
    "                one_hot_encoded_class = tf.one_hot(class_num, len(categories))\r\n",
    "                training_data.append([resized_img_arr, one_hot_encoded_class])\r\n",
    "            except Exception as e:\r\n",
    "                pass\r\n",
    "            \r\n",
    "    random.shuffle(training_data)\r\n",
    "        \r\n",
    "    X = []\r\n",
    "    y = []\r\n",
    "\r\n",
    "    for features, label in training_data:\r\n",
    "        X.append(features)\r\n",
    "        y.append(label)\r\n",
    "    \r\n",
    "    # for some reason regular lists dont work so we convert to np arrays\r\n",
    "    X = np.array(X).reshape(-1, img_size, img_size, channel_count)\r\n",
    "    y = np.array(y)\r\n",
    "    \r\n",
    "    print(f\"successfully processed {len(training_data)} photos in res {img_size}x{img_size}\")\r\n",
    "    \r\n",
    "    return (X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "X_gray, y_gray = create_training_data(cv2.IMREAD_GRAYSCALE)\r\n",
    "X_rgb, y_rgb = create_training_data(cv2.IMREAD_COLOR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "successfully processed 24946 photos in res 70x70\n",
      "successfully processed 24946 photos in res 70x70\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# pickle dump to save for later use\r\n",
    "pickle_out = open(\"X_gray.pickle\", \"wb\")\r\n",
    "pickle.dump(X_gray, pickle_out)\r\n",
    "pickle_out.close()\r\n",
    "\r\n",
    "pickle_out = open(\"y_gray.pickle\", \"wb\")\r\n",
    "pickle.dump(y_gray, pickle_out)\r\n",
    "pickle_out.close()\r\n",
    "\r\n",
    "pickle_out = open(\"X_rgb.pickle\", \"wb\")\r\n",
    "pickle.dump(X_rgb, pickle_out)\r\n",
    "pickle_out.close()\r\n",
    "\r\n",
    "pickle_out = open(\"y_rgb.pickle\", \"wb\")\r\n",
    "pickle.dump(y_rgb, pickle_out)\r\n",
    "pickle_out.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "if (len(tf.config.list_physical_devices('GPU')) == 0):\r\n",
    "    print('gpu not detected')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model optimization\n",
    "## Test different dense layers, layer sizes, conv layers (grayscale)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "X_gray = pickle.load(open(\"X_gray.pickle\", \"rb\"))\r\n",
    "y_gray = pickle.load(open(\"y_gray.pickle\", \"rb\"))\r\n",
    "X_gray = X_gray / 255.0\r\n",
    "\r\n",
    "dense_layer_options = [0, 1, 2]\r\n",
    "layer_size_options = [32, 64, 128]\r\n",
    "conv_layer_options = [1, 2, 3]\r\n",
    "\r\n",
    "earlystopping = EarlyStopping(monitor =\"val_loss\", \r\n",
    "                              mode =\"min\",\r\n",
    "                              patience = 5, \r\n",
    "                              restore_best_weights = True)\r\n",
    "\r\n",
    "\r\n",
    "for dense_layer in dense_layer_options:\r\n",
    "    for layer_size in layer_size_options:\r\n",
    "        for conv_layer in conv_layer_options:\r\n",
    "            model_name = f\"{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{int(time.time())}\"\r\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(model_name))\r\n",
    "\r\n",
    "            optimized_model = Sequential()\r\n",
    "            \r\n",
    "            optimized_model.add(Conv2D(layer_size, (3,3), input_shape=X_gray.shape[1:]))\r\n",
    "            optimized_model.add(Activation(\"relu\"))\r\n",
    "            optimized_model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "            \r\n",
    "            for l in range(conv_layer-1):\r\n",
    "                optimized_model.add(Conv2D(layer_size, (3,3)))\r\n",
    "                optimized_model.add(Activation(\"relu\"))\r\n",
    "                optimized_model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "            optimized_model.add(Flatten())\r\n",
    "            \r\n",
    "            for l in range(dense_layer):\r\n",
    "                optimized_model.add(Dense(layer_size))\r\n",
    "                optimized_model.add(Activation(\"relu\"))\r\n",
    "\r\n",
    "            optimized_model.add(Dense(len(categories)))\r\n",
    "            optimized_model.add(Activation(\"softmax\"))\r\n",
    "\r\n",
    "            optimized_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\r\n",
    "            optimized_model.fit(X_gray, y_gray, batch_size=32, epochs=10, validation_split=0.1, callbacks=[tensorboard, earlystopping])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.5962 - accuracy: 0.6814 - val_loss: 0.5300 - val_accuracy: 0.7407\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.5116 - accuracy: 0.7499 - val_loss: 0.5291 - val_accuracy: 0.7347\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.4786 - accuracy: 0.7724 - val_loss: 0.5209 - val_accuracy: 0.7395\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.4475 - accuracy: 0.7920 - val_loss: 0.5355 - val_accuracy: 0.7387\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.5188 - val_accuracy: 0.7431\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.4034 - accuracy: 0.8173 - val_loss: 0.5404 - val_accuracy: 0.7287\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.3804 - accuracy: 0.8316 - val_loss: 0.5636 - val_accuracy: 0.7327\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.3606 - accuracy: 0.8438 - val_loss: 0.5481 - val_accuracy: 0.7263\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.3416 - accuracy: 0.8513 - val_loss: 0.5492 - val_accuracy: 0.7355\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.3214 - accuracy: 0.8644 - val_loss: 0.5903 - val_accuracy: 0.7242\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 5s 6ms/step - loss: 0.6122 - accuracy: 0.6601 - val_loss: 0.5480 - val_accuracy: 0.7166\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.5050 - accuracy: 0.7566 - val_loss: 0.4752 - val_accuracy: 0.7727\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.4635 - accuracy: 0.7819 - val_loss: 0.4522 - val_accuracy: 0.7852\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.4325 - accuracy: 0.8005 - val_loss: 0.4478 - val_accuracy: 0.7872\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.4047 - accuracy: 0.8179 - val_loss: 0.4506 - val_accuracy: 0.7896\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.3859 - accuracy: 0.8264 - val_loss: 0.4362 - val_accuracy: 0.7956\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3647 - accuracy: 0.8385 - val_loss: 0.4418 - val_accuracy: 0.7988\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3471 - accuracy: 0.8485 - val_loss: 0.4400 - val_accuracy: 0.8052\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3314 - accuracy: 0.8537 - val_loss: 0.4304 - val_accuracy: 0.8048\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3111 - accuracy: 0.8650 - val_loss: 0.4454 - val_accuracy: 0.7996\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.6250 - accuracy: 0.6423 - val_loss: 0.5549 - val_accuracy: 0.7174\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.5190 - accuracy: 0.7472 - val_loss: 0.4903 - val_accuracy: 0.7611\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.4710 - accuracy: 0.7756 - val_loss: 0.4536 - val_accuracy: 0.7792\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.4399 - accuracy: 0.7960 - val_loss: 0.4432 - val_accuracy: 0.7860\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.4132 - accuracy: 0.8113 - val_loss: 0.4210 - val_accuracy: 0.7976\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.3902 - accuracy: 0.8214 - val_loss: 0.3970 - val_accuracy: 0.8168\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.3726 - accuracy: 0.8323 - val_loss: 0.4027 - val_accuracy: 0.8192\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3490 - accuracy: 0.8450 - val_loss: 0.3724 - val_accuracy: 0.8349\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3351 - accuracy: 0.8521 - val_loss: 0.3694 - val_accuracy: 0.8337\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3122 - accuracy: 0.8618 - val_loss: 0.3647 - val_accuracy: 0.8357\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 5s 6ms/step - loss: 0.5946 - accuracy: 0.6857 - val_loss: 0.5503 - val_accuracy: 0.7194\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.5109 - accuracy: 0.7543 - val_loss: 0.5224 - val_accuracy: 0.7515\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.4658 - accuracy: 0.7781 - val_loss: 0.5326 - val_accuracy: 0.7343\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.4313 - accuracy: 0.8023 - val_loss: 0.5542 - val_accuracy: 0.7319\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3954 - accuracy: 0.8203 - val_loss: 0.5199 - val_accuracy: 0.7483\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3645 - accuracy: 0.8368 - val_loss: 0.5396 - val_accuracy: 0.7467\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3309 - accuracy: 0.8571 - val_loss: 0.5529 - val_accuracy: 0.7383\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3046 - accuracy: 0.8711 - val_loss: 0.5821 - val_accuracy: 0.7246\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.2740 - accuracy: 0.8875 - val_loss: 0.5774 - val_accuracy: 0.7459\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.2502 - accuracy: 0.9009 - val_loss: 0.6183 - val_accuracy: 0.7315\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.5967 - accuracy: 0.6747 - val_loss: 0.5281 - val_accuracy: 0.7351\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.4991 - accuracy: 0.7575 - val_loss: 0.4765 - val_accuracy: 0.7739\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.4532 - accuracy: 0.7856 - val_loss: 0.4460 - val_accuracy: 0.7924\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.4215 - accuracy: 0.8082 - val_loss: 0.4697 - val_accuracy: 0.7731\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.3881 - accuracy: 0.8254 - val_loss: 0.4378 - val_accuracy: 0.8056\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.3638 - accuracy: 0.8400 - val_loss: 0.4485 - val_accuracy: 0.7996\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.3394 - accuracy: 0.8496 - val_loss: 0.4095 - val_accuracy: 0.8208\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.3178 - accuracy: 0.8615 - val_loss: 0.4642 - val_accuracy: 0.7920\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.3015 - accuracy: 0.8710 - val_loss: 0.4285 - val_accuracy: 0.8172\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.2783 - accuracy: 0.8840 - val_loss: 0.4335 - val_accuracy: 0.8257\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.6162 - accuracy: 0.6534 - val_loss: 0.5754 - val_accuracy: 0.6990\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.5045 - accuracy: 0.7554 - val_loss: 0.4622 - val_accuracy: 0.7808\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.4408 - accuracy: 0.7966 - val_loss: 0.4351 - val_accuracy: 0.8048\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.3902 - val_accuracy: 0.8261\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.3655 - accuracy: 0.8366 - val_loss: 0.3626 - val_accuracy: 0.8349\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.3368 - accuracy: 0.8523 - val_loss: 0.3463 - val_accuracy: 0.8413\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.3119 - accuracy: 0.8614 - val_loss: 0.3226 - val_accuracy: 0.8625\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2828 - accuracy: 0.8772 - val_loss: 0.3311 - val_accuracy: 0.8553\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2620 - accuracy: 0.8882 - val_loss: 0.3204 - val_accuracy: 0.8581\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2390 - accuracy: 0.8984 - val_loss: 0.3235 - val_accuracy: 0.8705\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.5943 - accuracy: 0.6822 - val_loss: 0.5527 - val_accuracy: 0.7142\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.5179 - accuracy: 0.7467 - val_loss: 0.5663 - val_accuracy: 0.7094\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 6s 9ms/step - loss: 0.4708 - accuracy: 0.7768 - val_loss: 0.5351 - val_accuracy: 0.7323\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.4243 - accuracy: 0.8033 - val_loss: 0.5543 - val_accuracy: 0.7279\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.3850 - accuracy: 0.8277 - val_loss: 0.5365 - val_accuracy: 0.7411\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.3444 - accuracy: 0.8483 - val_loss: 0.5683 - val_accuracy: 0.7291\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2981 - accuracy: 0.8760 - val_loss: 0.6040 - val_accuracy: 0.7259\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.2632 - accuracy: 0.8908 - val_loss: 0.6013 - val_accuracy: 0.7367\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.6088 - accuracy: 0.6631 - val_loss: 0.5881 - val_accuracy: 0.6826\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.5226 - accuracy: 0.7428 - val_loss: 0.4948 - val_accuracy: 0.7623\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4742 - accuracy: 0.7754 - val_loss: 0.4642 - val_accuracy: 0.7820\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4353 - accuracy: 0.7996 - val_loss: 0.4365 - val_accuracy: 0.7972\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4026 - accuracy: 0.8194 - val_loss: 0.4974 - val_accuracy: 0.7707\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.3756 - accuracy: 0.8318 - val_loss: 0.4827 - val_accuracy: 0.7884\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 7s 11ms/step - loss: 0.3518 - accuracy: 0.8453 - val_loss: 0.4443 - val_accuracy: 0.8040\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 7s 11ms/step - loss: 0.3312 - accuracy: 0.8538 - val_loss: 0.4688 - val_accuracy: 0.7944\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 7s 11ms/step - loss: 0.3139 - accuracy: 0.8626 - val_loss: 0.4614 - val_accuracy: 0.7904\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 9s 13ms/step - loss: 0.6159 - accuracy: 0.6494 - val_loss: 0.5125 - val_accuracy: 0.7495\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 8s 12ms/step - loss: 0.4870 - accuracy: 0.7643 - val_loss: 0.4380 - val_accuracy: 0.7936\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 8s 11ms/step - loss: 0.4163 - accuracy: 0.8092 - val_loss: 0.3962 - val_accuracy: 0.8261\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 8s 12ms/step - loss: 0.3686 - accuracy: 0.8356 - val_loss: 0.3690 - val_accuracy: 0.8425\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 8s 11ms/step - loss: 0.3240 - accuracy: 0.8557 - val_loss: 0.3436 - val_accuracy: 0.8501\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 8s 11ms/step - loss: 0.2896 - accuracy: 0.8768 - val_loss: 0.3746 - val_accuracy: 0.8317\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 8s 12ms/step - loss: 0.2491 - accuracy: 0.8951 - val_loss: 0.3496 - val_accuracy: 0.8473\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 8s 12ms/step - loss: 0.2195 - accuracy: 0.9087 - val_loss: 0.3892 - val_accuracy: 0.8413\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 8s 11ms/step - loss: 0.1862 - accuracy: 0.9246 - val_loss: 0.3962 - val_accuracy: 0.8477\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 8s 11ms/step - loss: 0.1521 - accuracy: 0.9383 - val_loss: 0.4121 - val_accuracy: 0.8497\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.6985 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.6094 - accuracy: 0.6610 - val_loss: 0.5249 - val_accuracy: 0.7371\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.5037 - accuracy: 0.7556 - val_loss: 0.4944 - val_accuracy: 0.7555\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.4536 - accuracy: 0.7874 - val_loss: 0.4515 - val_accuracy: 0.7848\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.4097 - accuracy: 0.8113 - val_loss: 0.4443 - val_accuracy: 0.7908\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3696 - accuracy: 0.8341 - val_loss: 0.4322 - val_accuracy: 0.7964\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.3256 - accuracy: 0.8568 - val_loss: 0.4343 - val_accuracy: 0.8020\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.2859 - accuracy: 0.8775 - val_loss: 0.5257 - val_accuracy: 0.7768\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.2439 - accuracy: 0.8988 - val_loss: 0.4883 - val_accuracy: 0.8060\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.2034 - accuracy: 0.9165 - val_loss: 0.5374 - val_accuracy: 0.7864\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 3s 5ms/step - loss: 0.1630 - accuracy: 0.9372 - val_loss: 0.5787 - val_accuracy: 0.7968\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.6081 - accuracy: 0.6592 - val_loss: 0.5248 - val_accuracy: 0.7391\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.4897 - accuracy: 0.7631 - val_loss: 0.4541 - val_accuracy: 0.7896\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.4391 - accuracy: 0.7959 - val_loss: 0.4682 - val_accuracy: 0.7764\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.4044 - accuracy: 0.8142 - val_loss: 0.3958 - val_accuracy: 0.8212\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.3691 - accuracy: 0.8313 - val_loss: 0.4166 - val_accuracy: 0.8092\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.3331 - accuracy: 0.8563 - val_loss: 0.3556 - val_accuracy: 0.8373\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.3063 - accuracy: 0.8636 - val_loss: 0.4766 - val_accuracy: 0.7900\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.2809 - accuracy: 0.8801 - val_loss: 0.3912 - val_accuracy: 0.8261\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.2520 - accuracy: 0.8943 - val_loss: 0.3824 - val_accuracy: 0.8357\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 4s 5ms/step - loss: 0.2272 - accuracy: 0.9050 - val_loss: 0.4072 - val_accuracy: 0.8337\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.6030 - accuracy: 0.6818 - val_loss: 0.5370 - val_accuracy: 0.7287\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.5016 - accuracy: 0.7556 - val_loss: 0.5238 - val_accuracy: 0.7371\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.4387 - accuracy: 0.7952 - val_loss: 0.5350 - val_accuracy: 0.7391\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.3676 - accuracy: 0.8334 - val_loss: 0.5523 - val_accuracy: 0.7415\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.2832 - accuracy: 0.8778 - val_loss: 0.5975 - val_accuracy: 0.7267\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.1996 - accuracy: 0.9196 - val_loss: 0.7161 - val_accuracy: 0.7186\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 4s 6ms/step - loss: 0.1168 - accuracy: 0.9572 - val_loss: 0.8141 - val_accuracy: 0.7439\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.6020 - accuracy: 0.6672 - val_loss: 0.6257 - val_accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.4989 - accuracy: 0.7589 - val_loss: 0.4685 - val_accuracy: 0.7743\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.4448 - accuracy: 0.7933 - val_loss: 0.4563 - val_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.3940 - accuracy: 0.8236 - val_loss: 0.4305 - val_accuracy: 0.8008\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.3414 - accuracy: 0.8510 - val_loss: 0.4562 - val_accuracy: 0.7784\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2861 - accuracy: 0.8776 - val_loss: 0.4467 - val_accuracy: 0.8072\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2252 - accuracy: 0.9074 - val_loss: 0.4903 - val_accuracy: 0.7924\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.1703 - accuracy: 0.9322 - val_loss: 0.6084 - val_accuracy: 0.7872\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.1164 - accuracy: 0.9572 - val_loss: 0.7193 - val_accuracy: 0.7956\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.6336 - accuracy: 0.6267 - val_loss: 0.6103 - val_accuracy: 0.6693\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.5097 - accuracy: 0.7487 - val_loss: 0.4799 - val_accuracy: 0.7711\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.4359 - accuracy: 0.7961 - val_loss: 0.4142 - val_accuracy: 0.8072\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.3840 - accuracy: 0.8246 - val_loss: 0.3827 - val_accuracy: 0.8285\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.3436 - accuracy: 0.8479 - val_loss: 0.3476 - val_accuracy: 0.8461\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.2981 - accuracy: 0.8696 - val_loss: 0.3302 - val_accuracy: 0.8581\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2627 - accuracy: 0.8872 - val_loss: 0.3376 - val_accuracy: 0.8605\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2247 - accuracy: 0.9069 - val_loss: 0.3256 - val_accuracy: 0.8689\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.1905 - accuracy: 0.9208 - val_loss: 0.3491 - val_accuracy: 0.8629\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 6s 8ms/step - loss: 0.1557 - accuracy: 0.9368 - val_loss: 0.4607 - val_accuracy: 0.8333\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 8s 11ms/step - loss: 0.6416 - accuracy: 0.6668 - val_loss: 0.5418 - val_accuracy: 0.7311\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.5176 - accuracy: 0.7473 - val_loss: 0.5122 - val_accuracy: 0.7499\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4637 - accuracy: 0.7807 - val_loss: 0.5018 - val_accuracy: 0.7491\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.4100 - accuracy: 0.8135 - val_loss: 0.5255 - val_accuracy: 0.7351\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.3522 - accuracy: 0.8437 - val_loss: 0.5514 - val_accuracy: 0.7355\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.2790 - accuracy: 0.8806 - val_loss: 0.6093 - val_accuracy: 0.7423\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.2112 - accuracy: 0.9127 - val_loss: 0.7276 - val_accuracy: 0.7259\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 7s 10ms/step - loss: 0.1430 - accuracy: 0.9457 - val_loss: 0.8576 - val_accuracy: 0.7303\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 9s 12ms/step - loss: 0.6463 - accuracy: 0.6270 - val_loss: 0.5965 - val_accuracy: 0.6858\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 8s 11ms/step - loss: 0.5591 - accuracy: 0.7130 - val_loss: 0.5105 - val_accuracy: 0.7523\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 8s 12ms/step - loss: 0.4733 - accuracy: 0.7733 - val_loss: 0.4788 - val_accuracy: 0.7683\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 8s 11ms/step - loss: 0.4061 - accuracy: 0.8140 - val_loss: 0.5145 - val_accuracy: 0.7671\n",
      "Epoch 5/10\n",
      "470/702 [===================>..........] - ETA: 2s - loss: 0.3368 - accuracy: 0.8519"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20976/609133510.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0moptimized_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0moptimized_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result: 3 conv 0 dense 128 layer size had least eval loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Try higher layer size options"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_gray = pickle.load(open(\"X_gray.pickle\", \"rb\"))\r\n",
    "y_gray = pickle.load(open(\"y_gray.pickle\", \"rb\"))\r\n",
    "\r\n",
    "X_gray = X_gray / 255.0\r\n",
    "layer_size_options = [256, 512, 1024]\r\n",
    "\r\n",
    "\r\n",
    "for layer_size in layer_size_options:\r\n",
    "    model_name = f\"3-conv-{layer_size}-nodes-0-dense-{int(time.time())}\"\r\n",
    "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(model_name))\r\n",
    "\r\n",
    "    optimized_model = Sequential()\r\n",
    "\r\n",
    "    optimized_model.add(Conv2D(layer_size, (3,3), input_shape = X_gray.shape[1:]))\r\n",
    "    optimized_model.add(Activation(\"relu\"))\r\n",
    "    optimized_model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    optimized_model.add(Conv2D(layer_size, (3,3)))\r\n",
    "    optimized_model.add(Activation(\"relu\"))\r\n",
    "    optimized_model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    optimized_model.add(Conv2D(layer_size, (3,3)))\r\n",
    "    optimized_model.add(Activation(\"relu\"))\r\n",
    "    optimized_model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    optimized_model.add(Flatten())\r\n",
    "\r\n",
    "    optimized_model.add(Dense(1))\r\n",
    "    optimized_model.add(Activation(\"softmax\"))\r\n",
    "\r\n",
    "    optimized_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\r\n",
    "    optimized_model.fit(X_gray, y_gray, batch_size=32, epochs=10, validation_split=0.1, callbacks=[tensorboard])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final results: 3 conv layers 64 layer size 0 dense"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final model structure"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_final_model(X):\r\n",
    "    \r\n",
    "    model = Sequential()\r\n",
    "\r\n",
    "    model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\r\n",
    "    model.add(Activation(\"relu\"))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    model.add(Conv2D(64, (3,3)))\r\n",
    "    model.add(Activation(\"relu\"))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    model.add(Conv2D(64, (3,3)))\r\n",
    "    model.add(Activation(\"relu\"))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "    model.add(Flatten())\r\n",
    "\r\n",
    "    model.add(Dense(len(categories)))\r\n",
    "    model.add(Activation(\"softmax\"))\r\n",
    "\r\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trying to see if rgb works better than grayscale"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_gray = pickle.load(open(\"X_gray.pickle\", \"rb\"))\r\n",
    "y_gray = pickle.load(open(\"y_gray.pickle\", \"rb\"))\r\n",
    "\r\n",
    "X_gray = X_gray / 255.0\r\n",
    "\r\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{3-conv-64-nodes-0-dense-gray}\")\r\n",
    "final_model_gray = get_final_model(X_gray)\r\n",
    "final_model_gray.fit(X_gray, y_gray, batch_size=32, epochs=10, validation_split=0.1, callbacks=[tensorboard])\r\n",
    "\r\n",
    "final_model_gray.save('./classifier-api/64x3-CNN.model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_rgb = pickle.load(open(\"X_rgb.pickle\", \"rb\"))\r\n",
    "y_rgb = pickle.load(open(\"y_rgb.pickle\", \"rb\"))\r\n",
    "\r\n",
    "X_rgb = X_rgb / 255.0\r\n",
    "\r\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{3-conv-64-nodes-0-dense-rgb}\")\r\n",
    "final_model_rgb = get_final_model(X_rgb)\r\n",
    "final_model_rgb.fit(X_rgb, y_rgb, batch_size=32, epochs=10, validation_split=0.1, callbacks=[tensorboard])\r\n",
    "\r\n",
    "final_model_rgb.save('./classifier-api/64x3-CNN-rgb.model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experimenting with the effects of normalized image size"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_size = 120\r\n",
    "X_gray_high_res, y_gray_high_res = create_training_data(cv2.IMREAD_GRAYSCALE)\r\n",
    "X_gray_high_res = X_gray_high_res / 255.0\r\n",
    "\r\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{3-conv-64-nodes-0-dense-grey-high-res}\")\r\n",
    "earlystopping = EarlyStopping(monitor =\"val_loss\", \r\n",
    "                              mode =\"min\",\r\n",
    "                              patience = 5, \r\n",
    "                              restore_best_weights = True)\r\n",
    "final_model_gray_high_res = get_final_model(X_gray_high_res)\r\n",
    "final_model_gray_high_res.fit(\r\n",
    "    X_gray_high_res,\r\n",
    "    y_gray_high_res,\r\n",
    "    batch_size=32,\r\n",
    "    epochs=6,\r\n",
    "    validation_split=0.1,\r\n",
    "    callbacks=[tensorboard, earlystopping])\r\n",
    "\r\n",
    "final_model_gray_high_res.save('./classifier-api/64x3-CNN-grey-high-res.model')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# literally not enough ram to run this\r\n",
    "\r\n",
    "# img_size = 120\r\n",
    "# X_rgb_high_res, y_rgb_high_res = create_training_data(cv2.IMREAD_COLOR)\r\n",
    "# X_rgb_high_res = X_rgb_high_res / 255.0\r\n",
    "\r\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{3-conv-64-nodes-0-dense-rgb-high-res}\")\r\n",
    "# earlystopping = EarlyStopping(monitor =\"val_loss\", \r\n",
    "#                               mode =\"min\",\r\n",
    "#                               patience = 5, \r\n",
    "#                               restore_best_weights = True)\r\n",
    "# final_model_rgb_high_res = get_final_model(X_rgb_high_res)\r\n",
    "# final_model_rgb_high_res.fit(\r\n",
    "#     X_rgb_high_res,\r\n",
    "#     X_rgb_high_res,\r\n",
    "#     batch_size=32,\r\n",
    "#     epochs=15,\r\n",
    "#     validation_split=0.1,\r\n",
    "#     callbacks=[tensorboard, earlystopping])\r\n",
    "\r\n",
    "# final_model_rgb_high_res.save('./classifier-api/64x3-CNN-rgb-high-res.model')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d49247185e16a54892fb9d9c77cb8c46c6c3b35c18854c811106b7a4b1eb8d45"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}